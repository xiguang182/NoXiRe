{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f3b448-699e-4af7-8d29-6cf360f35011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import struct\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c81b00c-960d-4da1-aebc-46a78b0db463",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/aria-noxi/001_2016-03-17_Paris/smile.novice.system.csv'\n",
    "pathe = './data/aria-noxi/001_2016-03-17_Paris/engagement.novice.gold.csv'\n",
    "bin_file = './data/aria-noxi/001_2016-03-17_Paris/novice.au.stream~'\n",
    "file_name = './test.csv'\n",
    "root = './data/aria-noxi'\n",
    "save_folder = './processed_data'\n",
    "# every sample folder should have these 9 files\n",
    "list_of_files = ['engagement.csv','expert.au.stream','expert.face.stream','expert.head.stream','expert.skel.stream','expert.video[crop].mp4','novice.au.stream','novice.face.stream','novice.head.stream','novice.skel.stream','expert.video[crop].mp4']\n",
    "debug = False\n",
    "list_of_pattern_dim = [('*au.stream~', 17), ('*head.stream~', 3), ('*face.stream~', 4041), ('*skel.stream~', 350)]\n",
    "modalities = ['au', 'head', 'face', 'skel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679980c0-bfec-4ad9-9aec-8a3dc7a9a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_directories(path):\n",
    "    return [f for f in os.listdir(root) if not os.path.isfile(os.path.join(root, f))]\n",
    "\n",
    "def time_to_frame(time):\n",
    "    return int(np.rint(time * 100 / 4))\n",
    "\n",
    "def get_save_path(path, prefix = 'processed_'):\n",
    "    head, tail = os.path.split(path)\n",
    "    tail = prefix + tail\n",
    "    return os.path.join(head, tail)\n",
    "\n",
    "def search_pattern(root, pattern):\n",
    "    all_path = []\n",
    "    samples = search_directories(root)\n",
    "    for sample in samples:\n",
    "        path_list = glob.glob(os.path.join(root, sample, pattern))\n",
    "        path_list.sort()\n",
    "        all_path.extend(path_list)\n",
    "    return all_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07511e6-3c56-44d7-a0fb-10c37e504f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream_save_path(path, save_folder):\n",
    "    head, tail = os.path.split(path)\n",
    "    _, sample = os.path.split(head)\n",
    "    tmp = tail.split('.')\n",
    "    ret = sample\n",
    "    for i in tmp[:-1]:\n",
    "        ret += '_' + i\n",
    "    ret += '.csv'\n",
    "    return os.path.join(save_folder, ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2b3d883-1fc6-42da-8c5e-5a036a2d584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all files for every sample (not the contents of files)\n",
    "def validate_integrity(root):\n",
    "    flag = True\n",
    "    samples = search_directories(root)\n",
    "    for sample in samples:\n",
    "        for file in list_of_files:\n",
    "            if os.path.isfile(os.path.join(root, sample, file)) is not True:\n",
    "                print(f'{sample} is missing {file}')\n",
    "                flag = False\n",
    "    return flag\n",
    "\n",
    "def binary_to_csv(path, save_path, dim, byte_num = 4):\n",
    "#     with open(path, 'rb') as f:\n",
    "#         val = f.read()\n",
    "#         print(len(val))\n",
    "    with open(path, 'rb') as f:\n",
    "        feat_list = []\n",
    "        while(True):\n",
    "            val = f.read(dim * byte_num)\n",
    "            if len(val) == 0:\n",
    "                break;\n",
    "            elif len(val) < (dim * byte_num):\n",
    "                print('incomplete feature sample (less than one sample bytes read)', len(val), path)\n",
    "                break;\n",
    "            feat_set = []\n",
    "            for i in range(0, dim * byte_num, 4):\n",
    "                num = struct.unpack('f', val[i:i+4])[0]\n",
    "                feat_set.append(num)\n",
    "\n",
    "            feat_list.append(feat_set)\n",
    "        df = pd.DataFrame(feat_list)\n",
    "#         print(df)\n",
    "        df.to_csv(save_path, index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb54cde8-22f3-4456-8369-ccc2c25b11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_len(root, list_of_pattern_dim = [('*au.stream~', 17), ('*head.stream~', 3), ('*face.stream~', 4041), ('*skel.stream~', 350)], debug = False):\n",
    "    samples = search_directories(root)\n",
    "    tmp = 0\n",
    "    flag = True\n",
    "    for sample in tqdm(samples):\n",
    "        \n",
    "        for pattern, dim in list_of_pattern_dim:\n",
    "            stream_list = glob.glob(os.path.join(root, sample, pattern))\n",
    "            for stream_ in stream_list:\n",
    "                if tmp == 0:\n",
    "                    tmp = os.path.getsize(stream_) / dim\n",
    "                else:\n",
    "                    if tmp != os.path.getsize(stream_) / dim:\n",
    "                        print(f'{sample} streams frame dismatch')\n",
    "                        flag = False\n",
    "        tmp = 0\n",
    "        # print(stream_list)\n",
    "        # print([os.path.getsize(f) for f in stream_list])\n",
    "        if debug:\n",
    "            break\n",
    "        return flag\n",
    "    \n",
    "#clean up processed binary stream\n",
    "def clean_up(save_folder = './processed_data'):\n",
    "    all_csv = glob.glob(os.path.join(save_folder, '*au.csv'))\n",
    "    all_csv.extend(glob.glob(os.path.join(save_folder, '*face.csv')))\n",
    "    all_csv.extend(glob.glob(os.path.join(save_folder, '*head.csv')))\n",
    "    all_csv.extend(glob.glob(os.path.join(save_folder, '*skel.csv')))\n",
    "    for path in all_csv:\n",
    "        os.remove(path)\n",
    "        \n",
    "def binary2csv(root, pattern, dim, debug = False, save_folder = './processed_data'):\n",
    "    bin_list = search_pattern(root, pattern)\n",
    "    dim = dim\n",
    "    for bin_ in tqdm(bin_list):\n",
    "\n",
    "        save_path = get_stream_save_path(bin_, save_folder)\n",
    "        binary_to_csv(bin_, save_path, dim)\n",
    "\n",
    "        if debug:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e17d425f-e0b2-41e1-84c0-35bba7410afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_integrity(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8d4e581-9ad7-429d-89e7-c43d06ea624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_to_csv(bin_file, file_name, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd71ec72-bf6f-4198-a6de-711434e6c70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [01:47<00:00,  1.50it/s]\n",
      "100%|██████████| 162/162 [00:24<00:00,  6.56it/s]\n",
      "100%|██████████| 162/162 [7:46:00<00:00, 172.60s/it]  \n",
      "100%|██████████| 162/162 [25:20<00:00,  9.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# clean_up()\n",
    "for pattern, dim in list_of_pattern_dim:\n",
    "    binary2csv(root, pattern, dim, debug = debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb65be9f-ba05-42cf-aa2b-062673dc8f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/81 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_len(root, list_of_pattern_dim, debug = debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81577cfa-bd83-4369-8fd9-1e13bce1e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_disturbance():\n",
    "#     all_csv = glob.glob(os.path.join(save_folder, '*au.csv'))\n",
    "#     all_csv.extend(glob.glob(os.path.join(save_folder, '*face.csv')))\n",
    "#     all_csv.extend(glob.glob(os.path.join(save_folder, '*head.csv')))\n",
    "#     all_csv.extend(glob.glob(os.path.join(save_folder, '*skel.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc501fe-ef16-42e4-abeb-4ea31d2ecb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c6fe16-dfb3-45b0-a1c5-e191bdcbf553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc11c260-bd65-4ccc-a8d8-1d3c07c4e96e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
